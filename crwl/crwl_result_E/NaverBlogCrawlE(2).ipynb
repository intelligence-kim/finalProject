{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import pandas as pd\n",
    "#import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_experimental_option(\"detach\", True)\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\n",
    "service = Service(executable_path=ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 함수\n",
    "def Crawl(k):\n",
    "    # k <- keyword\n",
    "    k = k.replace(' ','+')\n",
    "    browser = webdriver.Chrome(service=service,options=chrome_options)\n",
    "    browser.maximize_window()\n",
    "    url = f\"https://search.naver.com/search.naver?query={k}&nso=&where=blog&sm=tab_opt\"\n",
    "    browser.get(url)\n",
    "    browser.implicitly_wait(2)\n",
    "\n",
    "    titles = []\n",
    "    crwl_blog = []\n",
    "    # 스크롤 횟수 \n",
    "    print('스크롤 횟수 : 30')\n",
    "    for i in range(30):\n",
    "        browser.find_element(By.CSS_SELECTOR,\"body\").send_keys(Keys.END)\n",
    "        time.sleep(1)\n",
    "        browser.execute_script(\"return window.scrollY\")\n",
    "    links = browser.find_elements(By.CSS_SELECTOR,\"div.total_area > a\")\n",
    "    blog_url = []\n",
    "    for link in links:\n",
    "        link = link.get_attribute('href')\n",
    "        if 'blog.naver.com' in link:\n",
    "            blog_url.append(link)\n",
    "    \n",
    "    print('blog url 개수 : ', len(blog_url))\n",
    "    for i in range(len(blog_url)):\n",
    "        blog_text = ''\n",
    "        browser.get(blog_url[i])\n",
    "        browser.implicitly_wait(2.5)\n",
    "        browser.switch_to.frame(\"mainFrame\")\n",
    "        soup = BeautifulSoup(browser.page_source,'html.parser')\n",
    "        \n",
    "        # title 긁어 오기\n",
    "        title = soup.select(\"div.pcol1\")\n",
    "        for element in soup.select(\"div.pcol1\"):\n",
    "            text = element.get_text(strip=True)\n",
    "            titles.append(text)\n",
    "\n",
    "        # 본문 긁어 오기\n",
    "        text = soup.select(\"div.se-main-container\")\n",
    "        #text = soup.select('div.se-component-content') # 이웃추가까지 긁힘\n",
    "        for t in text:\n",
    "            blog_text += t.text\n",
    "        blog_text = re.sub('\\n+', ' ', blog_text)\n",
    "        blog_text = re.sub('\\u200b+', ' ', blog_text)\n",
    "        crwl_blog.append(blog_text)   \n",
    "\n",
    "    result = pd.DataFrame(zip(titles, crwl_blog), columns = ['title', 'content'])\n",
    "    browser.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToCsv(k, result):\n",
    "    '''\n",
    "    검색 결과 CSV 변환\n",
    "    폴더 있는지 확인 -> 없으면 생성 -> path에 저장하는 기능 추가하기\n",
    "    '''\n",
    "    #save_path = Path('crwl_result_E/')\n",
    "    save_name = k + '.csv'\n",
    "    pd.DataFrame(result).to_csv(save_name, encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스크롤 횟수 : 30\n",
      "blog url 개수 :  883\n",
      "스크롤 횟수 : 30\n",
      "blog url 개수 :  882\n",
      "스크롤 횟수 : 30\n",
      "blog url 개수 :  887\n",
      "스크롤 횟수 : 30\n",
      "blog url 개수 :  880\n",
      "스크롤 횟수 : 30\n",
      "blog url 개수 :  886\n",
      "스크롤 횟수 : 30\n",
      "blog url 개수 :  889\n",
      "스크롤 횟수 : 30\n",
      "blog url 개수 :  874\n",
      "스크롤 횟수 : 30\n",
      "blog url 개수 :  857\n"
     ]
    }
   ],
   "source": [
    "# 검색 리스트\n",
    "mbti_e = ['ENFP', 'ENFJ', 'ENTP', 'ENTJ',\n",
    "          'ESFP', 'ESFJ', 'ESTP', 'ESTJ']\n",
    "\n",
    "for k in mbti_e:\n",
    "    key = f\"{k} 특징\"\n",
    "    crwl_result = Crawl(key)\n",
    "    ToCsv(k, crwl_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
