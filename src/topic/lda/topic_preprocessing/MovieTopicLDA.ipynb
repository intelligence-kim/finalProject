{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import pickle\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pandas import DataFrame \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.callbacks import CoherenceMetric\n",
    "from gensim import corpora\n",
    "from gensim.models.callbacks import PerplexityMetric\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from IPython.display import clear_output\n",
    "import logging\n",
    "from ast import literal_eval\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopicModeling:\n",
    "    def __init__(self,path=None,movie_data=None):\n",
    "        self.stopwords=[]\n",
    "        file = open(f\"koreanStopwords2.txt\", \"r\")\n",
    "        while True:\n",
    "            line = file.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            self.stopwords.append(line.strip())\n",
    "        file.close()\n",
    "        self.original_path = path\n",
    "        self.kkma = Kkma()\n",
    "        self.mecab=Mecab()\n",
    "        if path != None:\n",
    "            self.mbti = pd.read_csv(self.original_path,index_col=0,header=0)\n",
    "        else:\n",
    "            self.movie = movie_data\n",
    "\n",
    "    def clean_text(self,text):\n",
    "        text=re.sub(r\"[^A-Za-z0-9가-힣.]|[xa0]\",\" \",text)\n",
    "        text =' '.join(text.split())\n",
    "        text = text.lstrip()\n",
    "        return text.lower()\n",
    "    \n",
    "    def sentence_split(self, text):\n",
    "        sentence = sum([],(text.split('.')))\n",
    "        sentence = list(filter(None, sentence))\n",
    "        return [s.strip() for s in sentence]\n",
    "    \n",
    "    def get_nouns(self,tokenizer, sentence):\n",
    "        tagged = tokenizer.pos(sentence)\n",
    "        nouns = [s for s, t in tagged if t in ['NNG', 'NNP', 'VA', 'XR'] and len(s) >1]\n",
    "        return nouns\n",
    "    \n",
    "    def get_nouns(self,tokenizer, sentence):\n",
    "        tagged = tokenizer.pos(sentence)\n",
    "        nouns = [s for s, t in tagged if t in ['NNG', 'NNP', 'VA', 'XR'] and len(s) >1]\n",
    "        nouns = [x for x in nouns if x not in self.stopwords]\n",
    "        return nouns\n",
    "    \n",
    "    def keyword_ext(self,mbti=None,movie_title=None,topic=5,passes=10,iterations=10):\n",
    "        keyword = []\n",
    "        if mbti != None:\n",
    "            print('hi')\n",
    "            mbti_ = literal_eval(self.mbti.loc[mbti]['contents'])\n",
    "            for key in mbti_:\n",
    "                keyword.append(self.get_nouns(self.mecab,key))\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                movie_ = literal_eval(self.movie)\n",
    "                if len(movie_)==1:\n",
    "                    movie_ = self.sentence_split(movie_[0])\n",
    "                    if len(movie_)==1:\n",
    "                        return ''\n",
    "                for key in movie_:\n",
    "                    keyword.append(self.get_nouns(self.mecab,key))\n",
    "            except:\n",
    "                return ''\n",
    "        dictionary = corpora.Dictionary(keyword)\n",
    "        dictionary.filter_extremes(no_below=2, no_above=0.3)\n",
    "        corpus = [dictionary.doc2bow(text) for text in keyword]\n",
    "        num_topics = topic\n",
    "        chunksize = 1000\n",
    "        passes = passes\n",
    "        iterations = iterations\n",
    "        eval_every = 0\n",
    "        try:\n",
    "            temp = dictionary[0]\n",
    "        except:\n",
    "            return ''\n",
    "\n",
    "            \n",
    "            \n",
    "        id2word = dictionary.id2token\n",
    "\n",
    "        model = LdaModel(\n",
    "            corpus=corpus,\n",
    "            id2word=id2word,\n",
    "            chunksize=chunksize,\n",
    "            alpha='auto',\n",
    "            eta='auto',\n",
    "            iterations=iterations,\n",
    "            num_topics=num_topics,\n",
    "            passes=passes,\n",
    "            eval_every=eval_every\n",
    "        )\n",
    "        return  model.top_topics(corpus)\n",
    "    \n",
    "    def clean_topic(self,topics):\n",
    "        topic_dict={}\n",
    "        for i in range(len(topics)):\n",
    "            if topics[i][1]>-10.0 and topics[i][1]<-1.5:\n",
    "                continue\n",
    "            for key,value in dict(topics[i][0]).items():\n",
    "                try:\n",
    "                    topic_dict[value] += key\n",
    "                except KeyError:\n",
    "                    topic_dict[value] = key\n",
    "        return topic_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mbti_list = ['ISTJ','ISFJ','INFJ','INTJ',\n",
    "                        'ISTP','ISFP','INFP','INTP',\n",
    "                        'ESTP','ESFP','ENFP','ENTP',\n",
    "                        'ESTJ','ESFJ','ENFJ','ENTJ']\n",
    "model = None\n",
    "df = pd.DataFrame()\n",
    "for mbti in mbti_list:\n",
    "    topic_list = []\n",
    "    model = TopicModeling(path='./mbti_final_data.csv')\n",
    "    topic = model.keyword_ext(mbti)\n",
    "    topic_list += topic\n",
    "\n",
    "    final_topic = model.clean_topic(topic_list)\n",
    "    topic_df = pd.DataFrame(final_topic.items(),columns=[[f'{mbti}_keyword',f'{mbti}_weight'],['keyword','weight']])\n",
    "    df = pd.concat([df,topic_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = pd.read_csv('./total_review.csv',index_col=0,header=0)\n",
    "movie.replace('[]',np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "count = 0\n",
    "col_names = ['Watcha_Contents','Naver_Contents','Tistory_Contents']\n",
    "not_found = {}\n",
    "for col in col_names:\n",
    "        df = pd.DataFrame()\n",
    "        count=0\n",
    "        for title,n_id in list(zip(movie.index,movie.nfid)):\n",
    "            clear_output()\n",
    "            print(f\"진행상황 = {col}_{count}번째\")\n",
    "            topic_list = []\n",
    "            model = TopicModeling(movie_data=movie[movie.nfid==n_id][col][0])\n",
    "\n",
    "            topic = model.keyword_ext(movie_title=title,topic=10,passes=50,iterations=100)\n",
    "\n",
    "            topic_list += topic\n",
    "            final_topic = model.clean_topic(topic_list)\n",
    "            topic_df = pd.DataFrame(final_topic.items(),columns=[[f'{title}_{n_id}_keyword',f'{title}_{n_id}_weight'],['keyword','weight']])\n",
    "            df = pd.concat([df,topic_df], axis=1)\n",
    "            count+=1\n",
    "        df.to_csv(f'{col}_topic3.csv',encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>nfid</th>\n",
       "      <th>Watcha_Contents</th>\n",
       "      <th>Naver_Title</th>\n",
       "      <th>Naver_Contents</th>\n",
       "      <th>Tistory_Title</th>\n",
       "      <th>Tistory_Contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>시그널</td>\n",
       "      <td>80987077</td>\n",
       "      <td>['돈 주고 표 끊고 봐야할거 같은 드라마', '앞으로 극의전개가 매우궁금하다 조금...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>조이</td>\n",
       "      <td>81046255</td>\n",
       "      <td>['여자가 사업을 좀 하겠다는데 짜식들이 방해를 하구 말이야', '구심력을 상실한 ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>히트</td>\n",
       "      <td>70020509</td>\n",
       "      <td>['신선하다. 여자배우들이 더 많이 영화에서 중심이 되면 좋겠다. 남자투톱영화 지겨...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>아가씨</td>\n",
       "      <td>80113804</td>\n",
       "      <td>['스포일러가 있어요!! 보기', '스포일러가 있어요!! 보기', '스포일러가 있어...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>도가니</td>\n",
       "      <td>70241118</td>\n",
       "      <td>['공론화했다는 것만으로도 가치있는 영화', '별4개를 매기면 뜨는 재밌어요! 는 ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>퀸메이커</td>\n",
       "      <td>81503026</td>\n",
       "      <td>['그 뻔하고 올드한 걸 김희애 문소리는 왜 이제서야 찍을 수 있었는지가 중요함.....</td>\n",
       "      <td>['넷플릭스 퀸메이커 후기 결말 전형적인 드라마 ', '퀸메이커 넷플릭스 서울시장하...</td>\n",
       "      <td>['넷플릭스 퀸메이커 후기 결말 전형적인 드라마 넷플릭스 오리지널 한국 드라마 추천...</td>\n",
       "      <td>['[드라마리뷰] 퀸메이커 등장인물, 시즌2, 결말, 몇부작, 은채령 배우?', '...</td>\n",
       "      <td>[\"*주의 강력한 스포가 포함되어있습니다.퀸메이커 결말 시즌2요즘 영화나 드라마에서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>닥터 차정숙</td>\n",
       "      <td>81682438</td>\n",
       "      <td>['엄정화 개멋있다.엄마들은 정말 대단한 존재이다.엄마도 나처럼 꿈이 있다는걸 잊으...</td>\n",
       "      <td>[' 번역탐구 넷플릭스 드라마 닥터 차정숙 3화 영어 자막 ', '닥터 차정숙 홀릭...</td>\n",
       "      <td>[' 번역탐구 넷플릭스 드라마 닥터 차정숙 3화 영어 자막 업템포글로벌 번역 닥터 ...</td>\n",
       "      <td>['JTBC 드라마 &lt;닥터 차정숙&gt; 줄거리, 등장인물 소개, 리뷰', '닥터 차정숙...</td>\n",
       "      <td>['의대생이었던 정숙은 혼전임신으로 인해 의대 졸업 후 20년 동안 평범한 가정주부...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>끝나지 않는 세 번째 데이트</td>\n",
       "      <td>81456532</td>\n",
       "      <td>['모든 데이트는 운명적이다. 그러나 어떤 데이트는 다른 데이트보다 더 운명적이다....</td>\n",
       "      <td>['끝나지 않는 세 번째 데이트 넷플릭스 짧은 요약 스포 있음 ', '끝나지 않는 ...</td>\n",
       "      <td>['끝나지 않는 세 번째 데이트 넷플릭스 짧은 요약 스포 있음 넷플릭스 영화 다큐시...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>나쁜엄마</td>\n",
       "      <td>81669775</td>\n",
       "      <td>['와 개잘만들었다', '모든 캐릭터를 절벽끝에 세워두고시작했는데 생각보다 절벽이 ...</td>\n",
       "      <td>['나쁜엄마 10화 ', '나쁜엄마 라미란 이도현의 복수 빅피쳐를 알게 된다 9회 ...</td>\n",
       "      <td>['나쁜엄마 10화 안녕하세요 여러분제가 제일 좋아하는 드라마중에 하나나쁜엄마 본방...</td>\n",
       "      <td>['넷플릭스 볼만한 드라마 [나쁜엄마] 줄거리, 결말 리뷰', '나쁜엄마 14회 마...</td>\n",
       "      <td>[\"등장인물~더 글로리 이후에 이도현배우가 출연한다고 나와서 더 보고 싶기도 했던 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>나는 신이다: 신이 배신한 사람들</td>\n",
       "      <td>81493078</td>\n",
       "      <td>['용기낸 자들을 위해서 더 많은 사람들이 봤으면 좋겠다-진짜로 안봐야하는 쾌락을 ...</td>\n",
       "      <td>['넷플릭스 나는 신이다 정명석 관련된 연예인 파문 ', ' 도젠생각 한 사람의 용...</td>\n",
       "      <td>['넷플릭스 나는 신이다 정명석 관련된 연예인 파문 기독교복음선교회 2인자 로 불리...</td>\n",
       "      <td>['나는 신이다: 신이 배신한 사람들 관람후기', '[넷플릭스,MBC 다큐멘터리]나...</td>\n",
       "      <td>['인간을 신으로 모신 신도들의 참혹한 이야기 4편나는 신이다: 신이 배신한 사람들...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1437 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title      nfid  \\\n",
       "0                    시그널  80987077   \n",
       "1                     조이  81046255   \n",
       "2                     히트  70020509   \n",
       "3                    아가씨  80113804   \n",
       "4                    도가니  70241118   \n",
       "...                  ...       ...   \n",
       "1432                퀸메이커  81503026   \n",
       "1433              닥터 차정숙  81682438   \n",
       "1434     끝나지 않는 세 번째 데이트  81456532   \n",
       "1435                나쁜엄마  81669775   \n",
       "1436  나는 신이다: 신이 배신한 사람들  81493078   \n",
       "\n",
       "                                        Watcha_Contents  \\\n",
       "0     ['돈 주고 표 끊고 봐야할거 같은 드라마', '앞으로 극의전개가 매우궁금하다 조금...   \n",
       "1     ['여자가 사업을 좀 하겠다는데 짜식들이 방해를 하구 말이야', '구심력을 상실한 ...   \n",
       "2     ['신선하다. 여자배우들이 더 많이 영화에서 중심이 되면 좋겠다. 남자투톱영화 지겨...   \n",
       "3     ['스포일러가 있어요!! 보기', '스포일러가 있어요!! 보기', '스포일러가 있어...   \n",
       "4     ['공론화했다는 것만으로도 가치있는 영화', '별4개를 매기면 뜨는 재밌어요! 는 ...   \n",
       "...                                                 ...   \n",
       "1432  ['그 뻔하고 올드한 걸 김희애 문소리는 왜 이제서야 찍을 수 있었는지가 중요함.....   \n",
       "1433  ['엄정화 개멋있다.엄마들은 정말 대단한 존재이다.엄마도 나처럼 꿈이 있다는걸 잊으...   \n",
       "1434  ['모든 데이트는 운명적이다. 그러나 어떤 데이트는 다른 데이트보다 더 운명적이다....   \n",
       "1435  ['와 개잘만들었다', '모든 캐릭터를 절벽끝에 세워두고시작했는데 생각보다 절벽이 ...   \n",
       "1436  ['용기낸 자들을 위해서 더 많은 사람들이 봤으면 좋겠다-진짜로 안봐야하는 쾌락을 ...   \n",
       "\n",
       "                                            Naver_Title  \\\n",
       "0                                                    []   \n",
       "1                                                    []   \n",
       "2                                                    []   \n",
       "3                                                    []   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "1432  ['넷플릭스 퀸메이커 후기 결말 전형적인 드라마 ', '퀸메이커 넷플릭스 서울시장하...   \n",
       "1433  [' 번역탐구 넷플릭스 드라마 닥터 차정숙 3화 영어 자막 ', '닥터 차정숙 홀릭...   \n",
       "1434  ['끝나지 않는 세 번째 데이트 넷플릭스 짧은 요약 스포 있음 ', '끝나지 않는 ...   \n",
       "1435  ['나쁜엄마 10화 ', '나쁜엄마 라미란 이도현의 복수 빅피쳐를 알게 된다 9회 ...   \n",
       "1436  ['넷플릭스 나는 신이다 정명석 관련된 연예인 파문 ', ' 도젠생각 한 사람의 용...   \n",
       "\n",
       "                                         Naver_Contents  \\\n",
       "0                                                    []   \n",
       "1                                                    []   \n",
       "2                                                    []   \n",
       "3                                                    []   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "1432  ['넷플릭스 퀸메이커 후기 결말 전형적인 드라마 넷플릭스 오리지널 한국 드라마 추천...   \n",
       "1433  [' 번역탐구 넷플릭스 드라마 닥터 차정숙 3화 영어 자막 업템포글로벌 번역 닥터 ...   \n",
       "1434  ['끝나지 않는 세 번째 데이트 넷플릭스 짧은 요약 스포 있음 넷플릭스 영화 다큐시...   \n",
       "1435  ['나쁜엄마 10화 안녕하세요 여러분제가 제일 좋아하는 드라마중에 하나나쁜엄마 본방...   \n",
       "1436  ['넷플릭스 나는 신이다 정명석 관련된 연예인 파문 기독교복음선교회 2인자 로 불리...   \n",
       "\n",
       "                                          Tistory_Title  \\\n",
       "0                                                    []   \n",
       "1                                                    []   \n",
       "2                                                    []   \n",
       "3                                                    []   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "1432  ['[드라마리뷰] 퀸메이커 등장인물, 시즌2, 결말, 몇부작, 은채령 배우?', '...   \n",
       "1433  ['JTBC 드라마 <닥터 차정숙> 줄거리, 등장인물 소개, 리뷰', '닥터 차정숙...   \n",
       "1434                                                 []   \n",
       "1435  ['넷플릭스 볼만한 드라마 [나쁜엄마] 줄거리, 결말 리뷰', '나쁜엄마 14회 마...   \n",
       "1436  ['나는 신이다: 신이 배신한 사람들 관람후기', '[넷플릭스,MBC 다큐멘터리]나...   \n",
       "\n",
       "                                       Tistory_Contents  \n",
       "0                                                    []  \n",
       "1                                                    []  \n",
       "2                                                    []  \n",
       "3                                                    []  \n",
       "4                                                    []  \n",
       "...                                                 ...  \n",
       "1432  [\"*주의 강력한 스포가 포함되어있습니다.퀸메이커 결말 시즌2요즘 영화나 드라마에서...  \n",
       "1433  ['의대생이었던 정숙은 혼전임신으로 인해 의대 졸업 후 20년 동안 평범한 가정주부...  \n",
       "1434                                                 []  \n",
       "1435  [\"등장인물~더 글로리 이후에 이도현배우가 출연한다고 나와서 더 보고 싶기도 했던 ...  \n",
       "1436  ['인간을 신으로 모신 신도들의 참혹한 이야기 4편나는 신이다: 신이 배신한 사람들...  \n",
       "\n",
       "[1437 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('./total_review.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
