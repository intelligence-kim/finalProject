{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "class NamuwikiCrwl:\n",
    "    def __init__(self):\n",
    "        self.dataset = load_dataset(\"heegyu/namuwiki\")\n",
    "        print('Dataload Check')\n",
    "        print(self.dataset[\"train\"][0])\n",
    "        self.mbti_list = ['ISTJ','ISFJ','INFJ','INTJ',\n",
    "                            'ISTP','ISFP','INFP','INTP',\n",
    "                            'ESTP','ESFP','ENFP','ENTP',\n",
    "                            'ESTJ','ESFJ','ENFJ','ENTJ']\n",
    "\n",
    "    def mbti_number(self)->list :\n",
    "        namuwiki_number = []\n",
    "        for i in tqdm(range(len(self.dataset['train'])),desc='find mbti number'):\n",
    "            if self.dataset['train'][i]['title'] in self.mbti_list:\n",
    "                namuwiki_number.append(i)\n",
    "        return namuwiki_number\n",
    "\n",
    "    def make_pandas(self,namuwiki_number:list)->object:\n",
    "        mbti_df = pd.DataFrame()\n",
    "        for i in tqdm(range(len(namuwiki_number)), desc='make pandas'):\n",
    "            title = self.dataset['train'][namuwiki_number[i]]['title']\n",
    "            content = self.dataset['train'][namuwiki_number[i]]['text']\n",
    "            mbti_=pd.DataFrame({'title':title, 'content':content}, index=[title])\n",
    "            mbti_df=pd.concat([mbti_df,mbti_],axis=0)\n",
    "        mbti_df.to_csv(\"namuwiki_mbti.csv\",encoding='utf-8')\n",
    "        return mbti_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/studio/.cache/huggingface/datasets/heegyu___parquet/heegyu--namuwiki-ad416814e2c61654/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataload Check\n",
      "{'title': '!', 'text': '#redirect 느낌표\\n', 'contributors': 'r:hoon12560,namubot', 'namespace': ''}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "find mbti number: 100%|██████████| 867024/867024 [00:58<00:00, 14902.86it/s]\n"
     ]
    }
   ],
   "source": [
    "dump_namuwiki = NamuwikiCrwl()\n",
    "number_list = dump_namuwiki.mbti_number()\n",
    "# mbti_df = dump_namuwiki.make_pandas(number_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/studio/.cache/huggingface/datasets/heegyu___parquet/heegyu--namuwiki-ad416814e2c61654/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.10it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"heegyu/namuwiki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "make pandas: 100%|██████████| 16/16 [00:00<00:00, 1391.03it/s]\n"
     ]
    }
   ],
   "source": [
    "mbti_df = pd.DataFrame()\n",
    "for i in tqdm(range(len(number_list)), desc='make pandas'):\n",
    "    title = dataset['train'][number_list[i]]['title']\n",
    "    content = dataset['train'][number_list[i]]['text'].split('\\n')\n",
    "    content = list(filter(None, content))\n",
    "    try:\n",
    "        content = content[content.index('== 개요 =='):content.index(f'== {title}에 해당하는 인물 ==')]\n",
    "    except ValueError:\n",
    "        try:\n",
    "            content = content[content.index('== 개요 =='):content.index(f'== {title}에 해당되는 인물 ==')]\n",
    "        except:\n",
    "            content = content[content.index('== 개요 =='):content.index(f'=== {title}에 해당하는 인물 ===')]\n",
    "    mbti_=pd.DataFrame({'title':title, 'content':[content]}, index=[title])\n",
    "    mbti_df=pd.concat([mbti_df,mbti_],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbti_df.to_csv('mbti_namuwiki.csv',encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
